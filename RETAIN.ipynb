{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/russpv/SafeDrug/blob/main/RETAIN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8PdC2GEVG4Y"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6lpl-j4Lyvu",
        "outputId": "81e43afa-e4ae-49ab-905f-50d1da29add9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon May  9 00:16:13 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n",
            "Collecting memory_profiler\n",
            "  Downloading memory_profiler-0.60.0.tar.gz (38 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory_profiler) (5.4.8)\n",
            "Building wheels for collected packages: memory-profiler\n",
            "  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for memory-profiler: filename=memory_profiler-0.60.0-py3-none-any.whl size=31284 sha256=2dfe7bcd602402e0c86d06fdeb20250593f10fb023ddab385c6e93033828fe03\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/2b/fb/326e30d638c538e69a5eb0aa47f4223d979f502bbdb403950f\n",
            "Successfully built memory-profiler\n",
            "Installing collected packages: memory-profiler\n",
            "Successfully installed memory-profiler-0.60.0\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')\n",
        "\n",
        "! pip install memory_profiler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DODS0ZHpVFiA"
      },
      "source": [
        "# Args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1XCfvJT2kYrk"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "def arg_parser():\n",
        "    \"\"\" Parse command line arguments\n",
        "\n",
        "    Outputs:\n",
        "        arguments {object} -- object containing command line arguments\n",
        "    \"\"\"\n",
        "\n",
        "    # Initializer\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # Add arguments here\n",
        "    parser.add_argument('--Test', action='store_true', default=False, help=\"test mode\")\n",
        "    parser.add_argument('--model_name', type=str, default='none', help=\"model name\")\n",
        "    parser.add_argument('--resume_path', type=str, default='none', help='resume path')\n",
        "    parser.add_argument('--lr', type=float, default=5e-4, help='learning rate')\n",
        "    parser.add_argument('--target_ddi', type=float, default=0.06, help=\"target ddi\")\n",
        "    parser.add_argument('--dropout', type=float, default=0.5, help=\"dropout for embeddings\")\n",
        "    parser.add_argument('--dim', type=int, default=64, help='dimension')\n",
        "    parser.add_argument('--cuda', type=int, default=0, help='which cuda') ###\n",
        "    parser.add_argument('--reverse', type=int, default=1, help='reverse input sequence') ###\n",
        "\n",
        "    parser.add_argument('--smalldata', type=int, default=1, help='debug data set') ###\n",
        "    parser.add_argument('--mydata', type=int, default=1, help='paper code') ###\n",
        "    parser.add_argument('--Inf_time', type=int, default=0, help='inference time test') ###\n",
        " \n",
        "    # Parse and return arguments\n",
        "    return(parser.parse_args(args=[]))\n",
        "\n",
        "args = arg_parser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WdztuWSRkwad"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import dill\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import pandas as pd\n",
        "import sys\n",
        "import time\n",
        "import statistics\n",
        "import datetime as dt\n",
        "import logging\n",
        "\n",
        "# set seed\n",
        "seed = 1203 #1203\n",
        "random.seed(seed)\n",
        "np.random.seed(seed) #2048\n",
        "torch.manual_seed(seed)\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "\n",
        "# define data path\n",
        "DATA_PATH = \"drive/MyDrive/DL4H/Project/PaperCode/processed_orig/\"\n",
        "MYDATA_PATH = \"drive/MyDrive/DL4H/Project/SAFEDRUG_lib/data/processed/\"\n",
        "WORKING_PATH = \"drive/MyDrive/DL4H/Project/RETAIN/\"\n",
        "TEST_PATH = \"drive/MyDrive/DL4H/Project/RETAIN/results/\"\n",
        "\n",
        "# define dataset\n",
        "args.mydata = 0\n",
        "args.smalldata = 0\n",
        "EPOCH = 50\n",
        "\n",
        "# define routine\n",
        "args.Test = True\n",
        "args.Inf_time = False\n",
        "\n",
        "# setting\n",
        "args.model_name = 'RETAIN_orig_rev'\n",
        "args.reverse = 1\n",
        "\n",
        "args.resume_path = WORKING_PATH + 'saved/' + 'RETAIN_orig_rev_0Epoch_44_TARGET_0.06_JA_0.4534_DDI_0.08434_2022-05-08 22:12:56.834379.model'\n",
        "# RETAIN_rev_1Epoch_44_TARGET_0.06_JA_0.4533_DDI_0.7759_2022-05-08 20:01:22.121790.model\n",
        "# RETAIN_rev_0Epoch_49_TARGET_0.06_JA_0.4582_DDI_0.7824_2022-05-08 17:17:16.110156.model\n",
        "logger = logging.getLogger('')\n",
        "logger.setLevel(logging.CRITICAL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5in3y_JEkx21"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBaou6BXkz1O",
        "outputId": "1ba5cd95-7b0e-446a-fde5-b84c4475c08b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nbp4RS5bk1Wc"
      },
      "outputs": [],
      "source": [
        "# Data switch\n",
        "if args.mydata == 1:\n",
        "    data_path = MYDATA_PATH + 'ehr.pkl'\n",
        "    voc_path = MYDATA_PATH + 'vocabs.pkl'\n",
        "\n",
        "    ehr_adj_path = MYDATA_PATH + 'ehradj.pkl'\n",
        "    ddi_adj_path = MYDATA_PATH + 'ddiadj.pkl'\n",
        "    ddi_mask_path = MYDATA_PATH + 'hmask.pkl'\n",
        "    molecule_path = MYDATA_PATH + 'atc2SMILES.pkl'\n",
        "\n",
        "    voc = dill.load(open(voc_path, 'rb'))\n",
        "    diag_voc, pro_voc, med_voc = voc['diag_vocab'].index2word, voc['pro_vocab'].index2word, voc['med_vocab'].index2word\n",
        "\n",
        "else:\n",
        "    data_path = DATA_PATH + 'records_final.pkl'\n",
        "    voc_path = DATA_PATH + 'voc_final.pkl'\n",
        "\n",
        "\n",
        "    ehr_adj_path = DATA_PATH + 'ehr_adj_final.pkl'\n",
        "    ddi_adj_path = DATA_PATH + 'ddi_A_final.pkl'\n",
        "    ddi_mask_path = DATA_PATH + 'ddi_mask_H.pkl'\n",
        "    molecule_path = DATA_PATH + 'atc3toSMILES.pkl'\n",
        "    \n",
        "    voc = dill.load(open(voc_path, 'rb'))\n",
        "    diag_voc, pro_voc, med_voc = voc['diag_voc'].idx2word, voc['pro_voc'].idx2word, voc['med_voc'].idx2word\n",
        "\n",
        "ehr_adj = dill.load(open(ehr_adj_path, 'rb'))\n",
        "ddi_adj = dill.load(open(ddi_adj_path, 'rb'))\n",
        "ddi_mask_H = dill.load(open(ddi_mask_path, 'rb'))\n",
        "data = dill.load(open(data_path, 'rb'))\n",
        "molecule = dill.load(open(molecule_path, 'rb')) \n",
        "\n",
        "if args.smalldata == 1:\n",
        "    data_train = data[:200] \n",
        "    data_test = data[200:250]\n",
        "    data_eval = data[250:300]\n",
        "else:\n",
        "    split_point = int(len(data) * 2 / 3)\n",
        "    data_train = data[:split_point]\n",
        "    eval_len = int(len(data[split_point:]) / 2)\n",
        "    data_test = data[split_point:split_point + eval_len]\n",
        "    data_eval = data[split_point+eval_len:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KJVEcp3k6eM"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LP4JTig5nJsB"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import jaccard_score, roc_auc_score, precision_score, f1_score, average_precision_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sys\n",
        "import warnings\n",
        "import dill\n",
        "from collections import Counter\n",
        "from collections import defaultdict\n",
        "import torch\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def get_n_params(model):\n",
        "    pp=0\n",
        "    for p in list(model.parameters()):\n",
        "        nn=1\n",
        "        for s in list(p.size()):\n",
        "            nn = nn*s\n",
        "        pp += nn\n",
        "    return pp\n",
        "\n",
        "# use the same metric from DMNC\n",
        "def llprint(message):\n",
        "    sys.stdout.write(message)\n",
        "    sys.stdout.flush()\n",
        "\n",
        "def transform_split(X, Y):\n",
        "    x_train, x_eval, y_train, y_eval = train_test_split(X, Y, train_size=2/3, random_state=1203)\n",
        "    x_eval, x_test, y_eval, y_test = train_test_split(x_eval, y_eval, test_size=0.5, random_state=1203)\n",
        "    return x_train, x_eval, x_test, y_train, y_eval, y_test\n",
        "\n",
        "def sequence_output_process(output_logits, filter_token):\n",
        "    pind = np.argsort(output_logits, axis=-1)[:, ::-1]\n",
        "\n",
        "    out_list = []\n",
        "    break_flag = False\n",
        "    for i in range(len(pind)):\n",
        "        if break_flag:\n",
        "            break\n",
        "        for j in range(pind.shape[1]):\n",
        "            label = pind[i][j]\n",
        "            if label in filter_token:\n",
        "                break_flag = True\n",
        "                break\n",
        "            if label not in out_list:\n",
        "                out_list.append(label)\n",
        "                break\n",
        "    y_pred_prob_tmp = []\n",
        "    for idx, item in enumerate(out_list):\n",
        "        y_pred_prob_tmp.append(output_logits[idx, item])\n",
        "    sorted_predict = [x for _, x in sorted(zip(y_pred_prob_tmp, out_list), reverse=True)]\n",
        "    return out_list, sorted_predict\n",
        "\n",
        "\n",
        "def sequence_metric(y_gt, y_pred, y_prob, y_label):\n",
        "    def average_prc(y_gt, y_label):\n",
        "        score = []\n",
        "        for b in range(y_gt.shape[0]):\n",
        "            target = np.where(y_gt[b]==1)[0]\n",
        "            out_list = y_label[b]\n",
        "            inter = set(out_list) & set(target)\n",
        "            prc_score = 0 if len(out_list) == 0 else len(inter) / len(out_list)\n",
        "            score.append(prc_score)\n",
        "        return score\n",
        "\n",
        "\n",
        "    def average_recall(y_gt, y_label):\n",
        "        score = []\n",
        "        for b in range(y_gt.shape[0]):\n",
        "            target = np.where(y_gt[b] == 1)[0]\n",
        "            out_list = y_label[b]\n",
        "            inter = set(out_list) & set(target)\n",
        "            recall_score = 0 if len(target) == 0 else len(inter) / len(target)\n",
        "            score.append(recall_score)\n",
        "        return score\n",
        "\n",
        "\n",
        "    def average_f1(average_prc, average_recall):\n",
        "        score = []\n",
        "        for idx in range(len(average_prc)):\n",
        "            if (average_prc[idx] + average_recall[idx]) == 0:\n",
        "                score.append(0)\n",
        "            else:\n",
        "                score.append(2*average_prc[idx]*average_recall[idx] / (average_prc[idx] + average_recall[idx]))\n",
        "        return score\n",
        "\n",
        "\n",
        "    def jaccard(y_gt, y_label):\n",
        "        score = []\n",
        "        for b in range(y_gt.shape[0]):\n",
        "            target = np.where(y_gt[b] == 1)[0]\n",
        "            out_list = y_label[b]\n",
        "            inter = set(out_list) & set(target)\n",
        "            union = set(out_list) | set(target)\n",
        "            jaccard_score = 0 if union == 0 else len(inter) / len(union)\n",
        "            score.append(jaccard_score)\n",
        "        return np.mean(score)\n",
        "\n",
        "    def f1(y_gt, y_pred):\n",
        "        all_micro = []\n",
        "        for b in range(y_gt.shape[0]):\n",
        "            all_micro.append(f1_score(y_gt[b], y_pred[b], average='macro'))\n",
        "        return np.mean(all_micro)\n",
        "\n",
        "    def roc_auc(y_gt, y_pred_prob):\n",
        "        all_micro = []\n",
        "        for b in range(len(y_gt)):\n",
        "            all_micro.append(roc_auc_score(y_gt[b], y_pred_prob[b], average='macro'))\n",
        "        return np.mean(all_micro)\n",
        "\n",
        "    def precision_auc(y_gt, y_prob):\n",
        "        all_micro = []\n",
        "        for b in range(len(y_gt)):\n",
        "            all_micro.append(average_precision_score(y_gt[b], y_prob[b], average='macro'))\n",
        "        return np.mean(all_micro)\n",
        "\n",
        "    def precision_at_k(y_gt, y_prob_label, k):\n",
        "        precision = 0\n",
        "        for i in range(len(y_gt)):\n",
        "            TP = 0\n",
        "            for j in y_prob_label[i][:k]:\n",
        "                if y_gt[i, j] == 1:\n",
        "                    TP += 1\n",
        "            precision += TP / k\n",
        "        return precision / len(y_gt)\n",
        "    try:\n",
        "        auc = roc_auc(y_gt, y_prob)\n",
        "    except ValueError:\n",
        "        auc = 0\n",
        "    p_1 = precision_at_k(y_gt, y_label, k=1)\n",
        "    p_3 = precision_at_k(y_gt, y_label, k=3)\n",
        "    p_5 = precision_at_k(y_gt, y_label, k=5)\n",
        "    f1 = f1(y_gt, y_pred)\n",
        "    prauc = precision_auc(y_gt, y_prob)\n",
        "    ja = jaccard(y_gt, y_label)\n",
        "    avg_prc = average_prc(y_gt, y_label)\n",
        "    avg_recall = average_recall(y_gt, y_label)\n",
        "    avg_f1 = average_f1(avg_prc, avg_recall)\n",
        "\n",
        "    return ja, prauc, np.mean(avg_prc), np.mean(avg_recall), np.mean(avg_f1)\n",
        "\n",
        "def ddi_rate_score(record, path=ddi_adj_path): ###\n",
        "    # ddi rate\n",
        "    ddi_A = dill.load(open(path, 'rb'))\n",
        "    all_cnt = 0\n",
        "    dd_cnt = 0\n",
        "    for patient in record:\n",
        "        for adm in patient:\n",
        "            med_code_set = adm\n",
        "            for i, med_i in enumerate(med_code_set):\n",
        "                for j, med_j in enumerate(med_code_set):\n",
        "                    if j <= i:\n",
        "                        continue\n",
        "                    all_cnt += 1\n",
        "                    if ddi_A[med_i, med_j] == 1 or ddi_A[med_j, med_i] == 1:\n",
        "                        dd_cnt += 1\n",
        "    if all_cnt == 0:\n",
        "        return 0\n",
        "    return dd_cnt / all_cnt\n",
        "\n",
        "def multi_label_metric(y_gt, y_pred, y_prob):\n",
        "\n",
        "    def jaccard(y_gt, y_pred):\n",
        "        score = []\n",
        "        for b in range(y_gt.shape[0]):\n",
        "            target = np.where(y_gt[b] == 1)[0]\n",
        "            out_list = np.where(y_pred[b] == 1)[0]\n",
        "            inter = set(out_list) & set(target)\n",
        "            union = set(out_list) | set(target)\n",
        "            jaccard_score = 0 if union == 0 else len(inter) / len(union)\n",
        "            score.append(jaccard_score)\n",
        "        return np.mean(score)\n",
        "\n",
        "    def average_prc(y_gt, y_pred):\n",
        "        score = []\n",
        "        for b in range(y_gt.shape[0]):\n",
        "            target = np.where(y_gt[b] == 1)[0]\n",
        "            out_list = np.where(y_pred[b] == 1)[0]\n",
        "            inter = set(out_list) & set(target)\n",
        "            prc_score = 0 if len(out_list) == 0 else len(inter) / len(out_list)\n",
        "            score.append(prc_score)\n",
        "        return score\n",
        "\n",
        "    def average_recall(y_gt, y_pred):\n",
        "        score = []\n",
        "        for b in range(y_gt.shape[0]):\n",
        "            target = np.where(y_gt[b] == 1)[0]\n",
        "            out_list = np.where(y_pred[b] == 1)[0]\n",
        "            inter = set(out_list) & set(target)\n",
        "            recall_score = 0 if len(target) == 0 else len(inter) / len(target)\n",
        "            score.append(recall_score)\n",
        "        return score\n",
        "\n",
        "    def average_f1(average_prc, average_recall):\n",
        "        score = []\n",
        "        for idx in range(len(average_prc)):\n",
        "            if average_prc[idx] + average_recall[idx] == 0:\n",
        "                score.append(0)\n",
        "            else:\n",
        "                score.append(2*average_prc[idx]*average_recall[idx] / (average_prc[idx] + average_recall[idx]))\n",
        "        return score\n",
        "\n",
        "    def f1(y_gt, y_pred):\n",
        "        all_micro = []\n",
        "        for b in range(y_gt.shape[0]):\n",
        "            all_micro.append(f1_score(y_gt[b], y_pred[b], average='macro'))\n",
        "        return np.mean(all_micro)\n",
        "\n",
        "    def roc_auc(y_gt, y_prob):\n",
        "        all_micro = []\n",
        "        for b in range(len(y_gt)):\n",
        "            all_micro.append(roc_auc_score(y_gt[b], y_prob[b], average='macro'))\n",
        "        return np.mean(all_micro)\n",
        "\n",
        "    def precision_auc(y_gt, y_prob):\n",
        "        all_micro = []\n",
        "        for b in range(len(y_gt)):\n",
        "            all_micro.append(average_precision_score(y_gt[b], y_prob[b], average='macro'))\n",
        "        return np.mean(all_micro)\n",
        "\n",
        "    def precision_at_k(y_gt, y_prob, k=3):\n",
        "        precision = 0\n",
        "        sort_index = np.argsort(y_prob, axis=-1)[:, ::-1][:, :k]\n",
        "        for i in range(len(y_gt)):\n",
        "            TP = 0\n",
        "            for j in range(len(sort_index[i])):\n",
        "                if y_gt[i, sort_index[i, j]] == 1:\n",
        "                    TP += 1\n",
        "            precision += TP / len(sort_index[i])\n",
        "        return precision / len(y_gt)\n",
        "\n",
        "    # roc_auc\n",
        "    try:\n",
        "        auc = roc_auc(y_gt, y_prob)\n",
        "    except:\n",
        "        auc = 0\n",
        "    # precision\n",
        "    p_1 = precision_at_k(y_gt, y_prob, k=1)\n",
        "    p_3 = precision_at_k(y_gt, y_prob, k=3)\n",
        "    p_5 = precision_at_k(y_gt, y_prob, k=5)\n",
        "    # macro f1\n",
        "    f1 = f1(y_gt, y_pred)\n",
        "    # precision\n",
        "    prauc = precision_auc(y_gt, y_prob)\n",
        "    # jaccard\n",
        "    ja = jaccard(y_gt, y_pred)\n",
        "    # pre, recall, f1\n",
        "    avg_prc = average_prc(y_gt, y_pred)\n",
        "    avg_recall = average_recall(y_gt, y_pred)\n",
        "    avg_f1 = average_f1(avg_prc, avg_recall)\n",
        "\n",
        "    return ja, prauc, np.mean(avg_prc), np.mean(avg_recall), np.mean(avg_f1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKmUGP1ok-tL"
      },
      "source": [
        "# Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9FPngoLemZ8K"
      },
      "outputs": [],
      "source": [
        "class RETAIN(nn.Module):\n",
        "    def __init__(self, diag_voc, pro_voc, med_voc, embedding_dim=64, dropout=0.5, device=torch.device('cpu:0')):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.diag_voc, self.pro_voc, self.med_voc  = len(diag_voc), len(pro_voc), len(med_voc)\n",
        "        self.vocab_len = self.diag_voc + self.pro_voc + self.med_voc\n",
        "\n",
        "        self.embedding = nn.Embedding(self.vocab_len + 1, embedding_dim, padding_idx=self.vocab_len) # account for pad value\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.rnn_a = nn.GRU(embedding_dim, embedding_dim, batch_first=True)\n",
        "        self.rnn_b = nn.GRU(embedding_dim, embedding_dim, batch_first=True)\n",
        "        self.att_a = nn.Linear(embedding_dim, 1)\n",
        "        self.att_b = nn.Linear(embedding_dim, embedding_dim)\n",
        "\n",
        "        self.fc = nn.Linear(embedding_dim, self.med_voc) # output medication codes, sigmoid in training\n",
        "    \n",
        "    def attention_sum(self, alpha, beta, rev_v, rev_masks):\n",
        "        '''\n",
        "        sums visit*embeddings into just embeddings\n",
        "\n",
        "        Arguments:\n",
        "            alpha: the alpha attention weights  (batch_size, seq_length, 1)\n",
        "            beta: the beta attention weights of shape (batch_size, seq_length, hidden_dim)\n",
        "            rev_v: the visit embeddings in reversed time of shape (batch_size, # visits, embedding_dim)\n",
        "        '''\n",
        "        applied = alpha * beta * rev_v # combine alpha and beta, broadcasted to (batch_size, visits, hidden_dim)\n",
        "        c = torch.sum(applied, dim=-2) # sum over visits for (batch_size, hidden_dim)\n",
        "\n",
        "        return c\n",
        "\n",
        "    def sum_embeddings_with_mask(self, x, masks):\n",
        "        x = x * masks.unsqueeze(-1)\n",
        "        x = torch.sum(x, dim = -2)\n",
        "        return x\n",
        "\n",
        "    def forward(self, seq_input):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            seq_input: visit sequence in forward time (visits, batch_size, code)\n",
        "        Outputs:\n",
        "            probs: probabilities of shape (batch_size)\n",
        "        \"\"\"\n",
        "        # Pad visits, create mask, reverse visits\n",
        "        max_input_len = max([(len(v[0]) + len(v[1]) + len(v[2])) for v in seq_input])\n",
        "        input_np = []\n",
        "        mask = []\n",
        "        for visit in seq_input:\n",
        "            input_tmp = []\n",
        "            input_tmp.extend(visit[0]) #diags\n",
        "            input_tmp.extend(list(np.array(visit[1]) + self.diag_voc)) #procs, offset code set\n",
        "            input_tmp.extend(list(np.array(visit[2]) + self.diag_voc + self.pro_voc)) #meds, offset code set\n",
        "            if args.reverse == 1:\n",
        "                input_tmp = list(reversed(input_tmp)) # reversed time\n",
        "            mask_tmp = [1 for c in input_tmp]\n",
        "            if len(input_tmp) < max_input_len:\n",
        "                padding = [self.vocab_len]*(max_input_len - len(input_tmp)) # zero taken, use next available number\n",
        "                mask_padding = [0 for x in padding]\n",
        "                input_tmp.extend( padding )\n",
        "                mask_tmp.extend( mask_padding )\n",
        "            input_np.append(input_tmp) # make list of lists\n",
        "            mask.append(mask_tmp)\n",
        "        input_np = torch.LongTensor(input_np).to(self.device)\n",
        "        mask = torch.LongTensor(mask).to(self.device)\n",
        "\n",
        "        logger.warning(f'\\nfinal input size: {input_np.size()}')\n",
        "        logger.warning(f'mask size: {mask.size()}')\n",
        "        \n",
        "        emb_v = self.embedding(input_np) #(visits, codes, embedding_dim)\n",
        "        emb_v = self.dropout(emb_v)\n",
        "        emb_v = self.sum_embeddings_with_mask(emb_v, mask) #( # visits, embedding_dim) \n",
        "\n",
        "        g, _ = self.rnn_a(emb_v.unsqueeze(dim=0)) #( 1, seq_length=visit, embedding dim)\n",
        "        h, _ = self.rnn_b(emb_v.unsqueeze(dim=0)) #( 1, seq_length=visit, embedding dim)\n",
        "        logger.warning(f'g size: {g.size()}')\n",
        "        logger.warning(f'h size: {h.size()}')\n",
        "        alpha = torch.softmax(self.att_a(g.squeeze(dim=0)), dim=1) #(seq_length=visit, embedding dim)\n",
        "        beta = torch.tanh(self.att_b(h.squeeze(dim=0))) #( seq_length=visit, embedding dim)\n",
        "        logger.warning(f'alpha size: {alpha.size()}')\n",
        "        logger.warning(f'beta size: {beta.size()}')\n",
        "        c = self.attention_sum(alpha, beta, emb_v, mask).unsqueeze(dim=0) #( hidden states)\n",
        "        logger.warning(f'c size: {c.size()}')\n",
        "        logits = self.fc(c)\n",
        "\n",
        "        logger.warning(f'output size: {logits.size()}')\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haCq6yPPlDdP"
      },
      "source": [
        "# Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LE8fvOl6lEYz"
      },
      "outputs": [],
      "source": [
        "from torch.optim import Adam\n",
        "import time\n",
        "\n",
        "# evaluate\n",
        "def eval(model, data_eval, voc_size, epoch):\n",
        "    model.eval()\n",
        "\n",
        "    smm_record = []\n",
        "    ja, prauc, avg_p, avg_r, avg_f1 = [[] for _ in range(5)]\n",
        "    med_cnt, visit_cnt = 0, 0\n",
        "\n",
        "    for step, input in enumerate(data_eval):\n",
        "        y_gt, y_pred, y_pred_prob, y_pred_label = [], [], [], []\n",
        "        \n",
        "        if len(input) < 2: continue # design requires more than one visit\n",
        "        for idx in range(1, len(input)): \n",
        "            target_output = model(input[:idx])\n",
        "\n",
        "            y_gt_tmp = np.zeros(voc_size[2])\n",
        "            y_gt_tmp[input[idx][2]] = 1\n",
        "            y_gt.append(y_gt_tmp)\n",
        "\n",
        "            # prediction prob\n",
        "            target_output = torch.sigmoid(target_output).detach().cpu().numpy()[0]\n",
        "            y_pred_prob.append(target_output)\n",
        "            \n",
        "            # prediction meds\n",
        "            y_pred_tmp = target_output.copy()\n",
        "            y_pred_tmp[y_pred_tmp>=0.5] = 1\n",
        "            y_pred_tmp[y_pred_tmp<0.5] = 0\n",
        "            y_pred.append(y_pred_tmp)\n",
        "\n",
        "            # prediction label\n",
        "            y_pred_label_tmp = np.where(y_pred_tmp == 1)[0]\n",
        "            y_pred_label.append(y_pred_label_tmp)\n",
        "            visit_cnt += 1\n",
        "            med_cnt += len(y_pred_label_tmp)\n",
        "\n",
        "        smm_record.append(y_pred_label)\n",
        "        adm_ja, adm_prauc, adm_avg_p, adm_avg_r, adm_avg_f1 = multi_label_metric(np.array(y_gt), np.array(y_pred), np.array(y_pred_prob))\n",
        "\n",
        "        ja.append(adm_ja)\n",
        "        prauc.append(adm_prauc)\n",
        "        avg_p.append(adm_avg_p)\n",
        "        avg_r.append(adm_avg_r)\n",
        "        avg_f1.append(adm_avg_f1)\n",
        "        llprint('\\rtest step: {} / {}'.format(step+1, len(data_eval)))\n",
        "\n",
        "    # ddi rate\n",
        "    ddi_rate = ddi_rate_score(smm_record, path=ddi_adj_path) ###\n",
        "\n",
        "    llprint('\\nDDI Rate: {:.4}, Jaccard: {:.4},  PRAUC: {:.4}, AVG_PRC: {:.4}, AVG_RECALL: {:.4}, AVG_F1: {:.4}, AVG_MED: {:.4}\\n'.format(\n",
        "        ddi_rate, np.mean(ja), np.mean(prauc), np.mean(avg_p), np.mean(avg_r), np.mean(avg_f1), med_cnt / visit_cnt\n",
        "    ))\n",
        "\n",
        "    return ddi_rate, np.mean(ja), np.mean(prauc), np.mean(avg_p), np.mean(avg_r), np.mean(avg_f1), med_cnt / visit_cnt\n",
        "\n",
        "def main():\n",
        "\n",
        "    device = torch.device(f'cuda:{args.cuda}' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    voc_size = (len(diag_voc), len(pro_voc), len(med_voc))\n",
        "    model = RETAIN(diag_voc, pro_voc, med_voc, args.dim, args.dropout, device=device)\n",
        "    # model.load_state_dict(torch.load(open(args.resume_path, 'rb')))\n",
        "\n",
        "    if args.Inf_time:\n",
        "        if 'cpu' in device.type:\n",
        "            print(f'Aborting inference timing, no GPU...')\n",
        "            return\n",
        "        #https://towardsdatascience.com/the-correct-way-to-measure-inference-time-of-deep-neural-networks-304a54e5187f\n",
        "        model.load_state_dict(torch.load(open(args.resume_path, 'rb')))\n",
        "        model.to(device=device)\n",
        "        tic = time.time()\n",
        "\n",
        "        starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
        "        repetitions = len(data_test)\n",
        "        timings = np.zeros((repetitions,1))\n",
        "        dummy_input = [[[13, 98, 585, 1065, 21, 37, 454, 278], [69, 47], [4, 22, 12, 2, 67, 0, 86]],\\\n",
        "                       [[377, 326, 21, 46, 454], [115, 94], [3, 6, 12, 14, 5, 22, 2, 29, 1, 16, 11, 86]],\\\n",
        "                       [[377, 246, 453, 46, 21, 454], [151, 127, 128], [14, 2, 6, 29, 18, 0, 86]], [[963, 258, 32, 93, 94, 13, 103, 571, 21], [164, 423, 424, 425, 95, 426, 361, 48, 46, 2], [5, 4, 6, 7, 9, 11, 12, 3, 13, 16, 14, 22, 1, 2, 29, 44, 45, 48, 56, 20, 76, 86]]]\n",
        "\n",
        "        #GPU-WARM-UP\n",
        "        for _ in range(10):\n",
        "            _ = model(dummy_input)\n",
        "        count = 0\n",
        "\n",
        "        # MEASURE PERFORMANCE\n",
        "        with torch.no_grad():\n",
        "            #for rep in range(repetitions):\n",
        "            for rep, example in enumerate(data_test):\n",
        "                starter.record()\n",
        "                _ = model(example)\n",
        "                ender.record()\n",
        "                # WAIT FOR GPU SYNC\n",
        "                torch.cuda.synchronize()\n",
        "                curr_time = starter.elapsed_time(ender)\n",
        "                timings[rep] = curr_time\n",
        "                count += 1\n",
        "\n",
        "        mean_syn = np.sum(timings) / repetitions\n",
        "        std_syn = np.std(timings)\n",
        "        print(f'Inference reps {count}, average: {mean_syn} \\u00B1 {std_syn} seconds')\n",
        "\n",
        "        data = np.array([mean_syn, std_syn, count])\n",
        "        df = pd.DataFrame(data, index=['mean inference time', 'stdev', 'reps'])\n",
        "        df.to_csv(TEST_PATH + 'Inf_' + args.model_name + device.type + f'{dt.datetime.now()}' + '.csv' )\n",
        "\n",
        "        return\n",
        "\n",
        "    if args.Test:\n",
        "        model.load_state_dict(torch.load(open(args.resume_path, 'rb')))\n",
        "        model.to(device=device)\n",
        "        tic = time.time()\n",
        "\n",
        "        ddi_list, ja_list, prauc_list, f1_list, med_list = [], [], [], [], []\n",
        "\n",
        "        result = []\n",
        "        for _ in range(10):\n",
        "            time_start = time.time()\n",
        "            test_sample = np.random.choice(data_test, round(len(data_test) * 0.8), replace=True)\n",
        "            ddi_rate, ja, prauc, avg_p, avg_r, avg_f1, avg_med = eval(model, test_sample, voc_size, 0)\n",
        "            time_sample = time.time() - time_start ###\n",
        "            result.append([ddi_rate, ja, avg_f1, prauc, avg_med, time_sample])\n",
        "            \n",
        "        result = np.array(result)\n",
        "        mean = result.mean(axis=0)\n",
        "        std = result.std(axis=0)\n",
        "\n",
        "        outstring = \"\"\n",
        "        for m, s in zip(mean, std):\n",
        "            outstring += \"{:.4f} \"u\"\\u00B1\"\" {:.4f} & \".format(m, s) ###\n",
        "\n",
        "        print(outstring)\n",
        "        time_round = time.time() - tic\n",
        "        print(f'test time: {time_round}')\n",
        "        \n",
        "        elapsed_time = [0. for _ in range(5)]\n",
        "        elapsed_time.append(time_round)\n",
        "        data = np.array([mean, std, elapsed_time])\n",
        "\n",
        "        df = pd.DataFrame(data, columns=['ddi', 'ja', 'prauc', 'f1', 'med', 'time'], index=['mean', 'std', 'seconds'])\n",
        "        df.to_csv(TEST_PATH + 'Test_' + args.model_name + device.type + f'{dt.datetime.now()}' + '.csv' )\n",
        "\n",
        "        return \n",
        "\n",
        "    if 'cpu' not in device.type:\n",
        "        torch.cuda.reset_peak_memory_stats() # flush \n",
        "    model.to(device=device)\n",
        "    print('parameters', sum(p.numel() for p in model.parameters() if p.requires_grad)) ###\n",
        "\n",
        "    # exit()\n",
        "    optimizer = Adam(list(model.parameters()), lr=args.lr)\n",
        "\n",
        "    # start iterations\n",
        "    history = defaultdict(list)\n",
        "    best_epoch, best_ja = 0, 0\n",
        "\n",
        "    times_train, times_eval = [], [] ###\n",
        "    for epoch in range(EPOCH):\n",
        "        time_start = time.time() ###\n",
        "        print('\\nepoch {} --------------------------'.format(epoch + 1))\n",
        "        model.train()\n",
        "       \n",
        "        for step, input in enumerate(data_train): \n",
        "            if len(input) < 2: continue # design requires more than one visit\n",
        "\n",
        "            loss = 0\n",
        "            for idx in range(1, len(input)): \n",
        "                seq_input = input[:idx]\n",
        "                loss_bce_target = np.zeros((1, voc_size[2]))\n",
        "                loss_bce_target[:, input[idx][2]] = 1 # take the next visit's drugs\n",
        "\n",
        "                result = model(seq_input)\n",
        "\n",
        "                loss += F.binary_cross_entropy_with_logits(result, torch.FloatTensor(loss_bce_target).to(device)) # accumulate all visits\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            llprint(f'\\rtraining step: {step+1} / {len(data_train)} loss: {loss} ') ###\n",
        "        \n",
        "        print()\n",
        "\n",
        "        time_end = time.time()  ###\n",
        "        ddi_rate, ja, prauc, avg_p, avg_r, avg_f1, avg_med = eval(model, data_eval, voc_size, epoch)\n",
        "        time_train = time_end - time_start ###\n",
        "        time_eval = time.time() - time_end  ###\n",
        "        print(f'training time: {time_train}, test time: {time_eval}, torch.device: {device}') ###\n",
        "\n",
        "        times_train.append(time_train) ###\n",
        "        times_eval.append(time_eval) ###\n",
        "\n",
        "        history['ja'].append(ja)\n",
        "        history['ddi_rate'].append(ddi_rate)\n",
        "        history['avg_p'].append(avg_p)\n",
        "        history['avg_r'].append(avg_r)\n",
        "        history['avg_f1'].append(avg_f1)\n",
        "        history['prauc'].append(prauc)\n",
        "        history['med'].append(avg_med)\n",
        "\n",
        "        if epoch >= 5:\n",
        "            print('ddi: {}, Med: {}, Ja: {}, F1: {}, PRAUC: {}'.format(\n",
        "                np.mean(history['ddi_rate'][-5:]),\n",
        "                np.mean(history['med'][-5:]),\n",
        "                np.mean(history['ja'][-5:]),\n",
        "                np.mean(history['avg_f1'][-5:]),\n",
        "                np.mean(history['prauc'][-5:])\n",
        "                ))\n",
        "\n",
        "        torch.save(model.state_dict(), open(WORKING_PATH +''.join(('saved/', args.model_name, '_', 'rev_'+str(args.reverse),\\\n",
        "            'Epoch_{}_TARGET_{:.2}_JA_{:.4}_DDI_{:.4}_{}.model'.format(epoch, args.target_ddi, ja, ddi_rate, dt.datetime.now()))), 'wb')) ###\n",
        "\n",
        "        if epoch != 0 and best_ja < ja:\n",
        "            best_epoch = epoch\n",
        "            best_ja = ja\n",
        "\n",
        "        print('best_epoch: {}'.format(best_epoch))\n",
        "\n",
        "    dill.dump(history, open(WORKING_PATH +'history_{}_{}.pkl'.format(args.model_name, dt.datetime.now()), 'wb')) ###\n",
        "    \n",
        "    timings = np.array(list(zip(times_train, times_eval))) ###\n",
        "    df = pd.DataFrame(timings, columns=['train', 'test']) ###\n",
        "    df.to_csv(TEST_PATH + 'TimesTrain_' + args.model_name + f'{dt.datetime.now()}' + '.csv' ) ###\n",
        "\n",
        "    # Maximum cuda memory allocated\n",
        "    if 'cpu' not in device.type:\n",
        "        print(f'peak training memory allocated: {torch.cuda.max_memory_allocated(device)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XivxglhLB1rm"
      },
      "source": [
        "# Execute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl3kTnoqzkLy",
        "outputId": "e104215d-d1d2-42b0-c1d7-cf504a16eff9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test step: 846 / 846\n",
            "DDI Rate: 0.08359, Jaccard: 0.4467,  PRAUC: 0.7507, AVG_PRC: 0.7391, AVG_RECALL: 0.555, AVG_F1: 0.6107, AVG_MED: 15.27\n",
            "test step: 846 / 846\n",
            "DDI Rate: 0.08479, Jaccard: 0.4447,  PRAUC: 0.7555, AVG_PRC: 0.7447, AVG_RECALL: 0.5471, AVG_F1: 0.6086, AVG_MED: 15.26\n",
            "test step: 846 / 846\n",
            "DDI Rate: 0.08406, Jaccard: 0.4437,  PRAUC: 0.7439, AVG_PRC: 0.7345, AVG_RECALL: 0.5499, AVG_F1: 0.6074, AVG_MED: 15.35\n",
            "test step: 846 / 846\n",
            "DDI Rate: 0.09188, Jaccard: 0.4531,  PRAUC: 0.7557, AVG_PRC: 0.7465, AVG_RECALL: 0.5587, AVG_F1: 0.617, AVG_MED: 15.48\n",
            "test step: 846 / 846\n",
            "DDI Rate: 0.08521, Jaccard: 0.443,  PRAUC: 0.7528, AVG_PRC: 0.7426, AVG_RECALL: 0.548, AVG_F1: 0.607, AVG_MED: 14.99\n",
            "test step: 846 / 846\n",
            "DDI Rate: 0.08377, Jaccard: 0.4475,  PRAUC: 0.7598, AVG_PRC: 0.7507, AVG_RECALL: 0.5503, AVG_F1: 0.6118, AVG_MED: 14.87\n",
            "test step: 846 / 846\n",
            "DDI Rate: 0.08435, Jaccard: 0.4448,  PRAUC: 0.7564, AVG_PRC: 0.7433, AVG_RECALL: 0.5504, AVG_F1: 0.6087, AVG_MED: 15.38\n",
            "test step: 846 / 846\n",
            "DDI Rate: 0.08281, Jaccard: 0.445,  PRAUC: 0.7526, AVG_PRC: 0.7453, AVG_RECALL: 0.549, AVG_F1: 0.6095, AVG_MED: 14.85\n",
            "test step: 846 / 846\n",
            "DDI Rate: 0.08667, Jaccard: 0.4484,  PRAUC: 0.7551, AVG_PRC: 0.7417, AVG_RECALL: 0.5556, AVG_F1: 0.6119, AVG_MED: 15.43\n",
            "test step: 846 / 846\n",
            "DDI Rate: 0.08379, Jaccard: 0.452,  PRAUC: 0.758, AVG_PRC: 0.7405, AVG_RECALL: 0.5657, AVG_F1: 0.6159, AVG_MED: 15.39\n",
            "0.0851 ± 0.0025 & 0.4469 ± 0.0033 & 0.6109 ± 0.0032 & 0.7541 ± 0.0042 & 15.2285 ± 0.2230 & 5.4472 ± 0.1304 & \n",
            "test time: 54.472628355026245\n",
            "peak memory: 2779.97 MiB, increment: 0.26 MiB\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    %reload_ext memory_profiler\n",
        "    %memit -r1 main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trh2z0kkQII0",
        "outputId": "4124b2c9-ddb9-4c2a-9a48-cfec737d2b0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon May  9 00:17:53 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    34W / 250W |    949MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RETAIN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPtz6RIXNVT1UDJ1eZL8EnN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}